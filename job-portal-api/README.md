# Job Portal API - RESTful Job Listing Platform

A complete RESTful API for a job listing and application platform similar to Indeed, built with FastAPI, Docker, and following REST best practices.

## ğŸ¯ Features

### Core Functionality

- âœ… **Job Seekers Management** - Create profiles, upload resumes
- âœ… **Employers Management** - Company profiles and job posting
- âœ… **Job Postings** - Full CRUD with filtering (location, type, status)
- âœ… **Applications** - Submit applications with resume uploads
- âœ… **File Storage** - PDF resume storage and retrieval
- âœ… **HATEOAS** - Hypermedia links for resource navigation

### RESTful Design Principles

| Principle           | Implementation                                       |
| ------------------- | ---------------------------------------------------- |
| **Resource Naming** | Proper noun-based URLs (`/api/jobs`, `/api/seekers`) |
| **HTTP Methods**    | GET, POST, PUT, PATCH, DELETE correctly mapped       |
| **Statelessness**   | No server-side session storage                       |
| **HATEOAS**         | Related resource links in responses                  |
| **Status Codes**    | 200, 201, 204, 400, 404 appropriately used           |

## ï¿½ Project Structure

```
job-portal-api/
â”œâ”€â”€ app/                      # Application code
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â”œâ”€â”€ models.py            # Pydantic models & schemas
â”‚   â”œâ”€â”€ database.py          # Database connection & initialization
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ routes/              # API route handlers
â”‚       â”œâ”€â”€ jobs.py         # Job posting endpoints
â”‚       â”œâ”€â”€ employers.py    # Employer endpoints
â”‚       â”œâ”€â”€ seekers.py      # Job seeker endpoints
â”‚       â””â”€â”€ applications.py # Application endpoints
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ README.md            # Scripts documentation
â”‚   â”œâ”€â”€ demo.sh             # Quick API demonstration
â”‚   â”œâ”€â”€ test_api.sh         # Comprehensive test suite
â”‚   â””â”€â”€ inspect_db.sh       # Database inspection tool
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ README.md            # Documentation guide
â”‚   â”œâ”€â”€ PROJECT_COMPLETE.md # Project completion summary
â”‚   â””â”€â”€ DATABASE_PERSISTENCE.md # Storage & persistence guide
â”œâ”€â”€ Dockerfile               # Container image definition
â”œâ”€â”€ docker-compose.yml       # Multi-container orchestration
â””â”€â”€ README.md               # This file
```

## ï¿½ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose installed
- Port 8000 available

### Run with Docker (Recommended)

```bash
# Navigate to project directory
cd job-portal-api

# Build and start the containers
docker compose up -d --build

# Wait for API to start
sleep 5

# Run demo to see it in action
./scripts/demo.sh

# Access the API
# Swagger UI: http://localhost:8000/docs
# ReDoc: http://localhost:8000/redoc
```

### Run Locally (Without Docker)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r app/requirements.txt

# Run the application
cd app
uvicorn main:app --reload

# Access: http://localhost:8000/docs
```

## ğŸ“š API Documentation

### Base URL

```
http://localhost:8000
```

### Main Endpoints

#### Job Seekers

```http
POST   /api/seekers              # Create job seeker profile
GET    /api/seekers              # List all seekers
GET    /api/seekers/{id}         # Get seeker details
PUT    /api/seekers/{id}         # Update seeker profile
DELETE /api/seekers/{id}         # Delete seeker
POST   /api/seekers/{id}/upload-resume  # Upload resume (PDF)
```

#### Employers

```http
POST   /api/employers            # Create employer profile
GET    /api/employers            # List all employers
GET    /api/employers/{id}       # Get employer details
PUT    /api/employers/{id}       # Update employer profile
DELETE /api/employers/{id}       # Delete employer
```

#### Job Postings

```http
POST   /api/jobs                 # Create job posting
GET    /api/jobs                 # List all jobs (with filters)
GET    /api/jobs/{id}            # Get job details
PUT    /api/jobs/{id}            # Update job posting
PATCH  /api/jobs/{id}/status     # Update job status
DELETE /api/jobs/{id}            # Delete job posting
GET    /api/jobs/{id}/applications  # Get job applications
```

**Query Parameters for GET /api/jobs:**

- `status` - Filter by status (open, closed, filled)
- `location` - Filter by location
- `job_type` - Filter by type (full-time, part-time, contract)
- `skip` - Pagination offset
- `limit` - Results per page

#### Applications

```http
POST   /api/applications         # Submit application
GET    /api/applications         # List applications (with filters)
GET    /api/applications/{id}    # Get application details
PATCH  /api/applications/{id}/status  # Update status (employer action)
DELETE /api/applications/{id}    # Withdraw application
POST   /api/applications/{id}/upload-resume  # Upload resume
```

**Query Parameters for GET /api/applications:**

- `seeker_id` - Filter by job seeker
- `job_id` - Filter by job posting
- `status` - Filter by status (pending, reviewed, accepted, rejected)

## ğŸ§ª Testing the API

### Using Swagger UI

1. Open browser: http://localhost:8000/docs
2. Explore endpoints with interactive documentation
3. Click "Try it out" on any endpoint
4. Fill in parameters and execute requests

### Example Workflow

```bash
# 1. Create an employer
curl -X POST http://localhost:8000/api/employers \
  -H "Content-Type: application/json" \
  -d '{
    "company_name": "Tech Corp",
    "email": "hr@techcorp.com",
    "phone": "555-0100",
    "description": "Leading tech company",
    "website": "https://techcorp.com"
  }'

# 2. Create a job posting (use employer_id from response)
curl -X POST http://localhost:8000/api/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "employer_id": 1,
    "title": "Senior Python Developer",
    "description": "Build scalable APIs",
    "requirements": ["Python", "FastAPI", "Docker"],
    "location": "Remote",
    "salary_range": "$100k-$150k",
    "job_type": "full-time",
    "experience_required": 5
  }'

# 3. Create a job seeker
curl -X POST http://localhost:8000/api/seekers \
  -H "Content-Type: application/json" \
  -d '{
    "name": "John Doe",
    "email": "john@example.com",
    "phone": "555-0123",
    "skills": ["Python", "FastAPI", "React"],
    "experience_years": 6
  }'

# 4. Upload resume for seeker
curl -X POST http://localhost:8000/api/seekers/1/upload-resume \
  -F "file=@resume.pdf"

# 5. Apply for job
curl -X POST http://localhost:8000/api/applications \
  -H "Content-Type: application/json" \
  -d '{
    "job_id": 1,
    "seeker_id": 1,
    "cover_letter": "I am excited to apply..."
  }'
```

## ğŸ—ï¸ Project Structure

```
job-portal-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â”œâ”€â”€ models.py            # Pydantic models & schemas
â”‚   â”œâ”€â”€ database.py          # Database setup & connection
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ jobs.py          # Job posting endpoints
â”‚   â”‚   â”œâ”€â”€ employers.py     # Employer endpoints
â”‚   â”‚   â”œâ”€â”€ seekers.py       # Job seeker endpoints
â”‚   â”‚   â””â”€â”€ applications.py  # Application endpoints
â”‚   â”œâ”€â”€ storage/             # File storage directory
â”‚   â”‚   â”œâ”€â”€ resumes/         # Job seeker resumes
â”‚   â”‚   â””â”€â”€ application_resumes/  # Application resumes
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile               # Container configuration
â”œâ”€â”€ docker-compose.yml       # Docker Compose setup
â””â”€â”€ README.md
```

## ğŸ—„ï¸ Database Schema

### Tables

**job_seekers**

- id, name, email, phone, skills (JSON), experience_years, resume_url, created_at

**employers**

- id, company_name, email, phone, description, website, created_at

**job_postings**

- id, employer_id (FK), title, description, requirements (JSON), location, salary_range, job_type, experience_required, status, created_at, updated_at

**applications**

- id, job_id (FK), seeker_id (FK), cover_letter, resume_url, status, applied_at

## ğŸ“¦ Docker Configuration

### Services

- **jobapi** - FastAPI application container
- **db** (optional) - PostgreSQL database (commented out by default)

### Volumes

- `./app` - Application code (for hot reload)
- `./app/storage` - Persistent file storage
- `./jobportal.db` - SQLite database file

### Environment Variables

- `PYTHONUNBUFFERED=1` - Real-time logging

## ğŸ”§ Configuration

### Switch to PostgreSQL (Production)

1. Uncomment PostgreSQL service in `docker-compose.yml`
2. Install `psycopg2-binary` in `requirements.txt`
3. Update `database.py` to use PostgreSQL connection
4. Run migrations

```bash
docker-compose up --build
```

## ğŸ¨ HATEOAS Implementation

Example response with hypermedia links:

```json
{
  "id": 1,
  "title": "Senior Python Developer",
  "employer_id": 1,
  "status": "open",
  "links": {
    "self": "http://localhost:8000/api/jobs/1",
    "employer": "http://localhost:8000/api/employers/1",
    "applications": "http://localhost:8000/api/jobs/1/applications",
    "apply": "http://localhost:8000/api/applications"
  }
}
```

## ğŸ› ï¸ Development Commands

```bash
# View logs
docker-compose logs -f

# Stop containers
docker-compose down

# Rebuild containers
docker-compose up --build

# Access container shell
docker exec -it job-portal-api bash

# Run database migrations (if using PostgreSQL)
docker-compose exec jobapi alembic upgrade head
```

## ğŸ“Š API Statistics

- **Total Endpoints**: 25+
- **Resource Types**: 4 (Seekers, Employers, Jobs, Applications)
- **HTTP Methods Used**: GET, POST, PUT, PATCH, DELETE
- **File Upload Support**: PDF resumes
- **Database**: SQLite (default) / PostgreSQL (optional)

## ğŸš¦ Next Steps (Phase 6 - Kubernetes)

Ready to deploy to Kubernetes? Let me know when you want to proceed with:

- Kubernetes deployment configuration
- Service and Ingress setup
- Persistent volume claims
- Minikube local deployment

## ğŸ“ Notes

- Default database: SQLite (`jobportal.db`)
- File storage: Local filesystem
- Authentication: Not implemented (add JWT for production)
- Rate limiting: Not implemented (add for production)

## ğŸ“š Additional Documentation

For more detailed information, see:

- **[Scripts Documentation](scripts/README.md)** - How to use demo, test, and inspection scripts
- **[Project Completion Summary](docs/PROJECT_COMPLETE.md)** - Full project status and implementation details
- **[Database Persistence Guide](docs/DATABASE_PERSISTENCE.md)** - Storage, backup, and data management
- **[Resume Upload Guide](docs/RESUME_UPLOAD_GUIDE.md)** - How to upload resumes with applications
- **[Swagger File Upload Guide](docs/SWAGGER_FILE_UPLOAD.md)** - Step-by-step Swagger UI file upload
- **[Documentation Index](docs/README.md)** - Complete documentation navigation

### Quick Links
- ğŸ”§ [Run Demo](scripts/demo.sh) - `./scripts/demo.sh`
- ğŸ§ª [Run Tests](scripts/test_api.sh) - `./scripts/test_api.sh`
- ğŸ” [Inspect Database](scripts/inspect_db.sh) - `./scripts/inspect_db.sh`
- ğŸ“– [Swagger UI](http://localhost:8000/docs) - Interactive API docs
- ğŸ“˜ [ReDoc](http://localhost:8000/redoc) - Clean API reference
- ğŸ“¤ [Upload File in Swagger](docs/SWAGGER_FILE_UPLOAD.md) - File upload guide

## ğŸ¤ Contributing

This is an assignment project demonstrating RESTful API design principles.

## ğŸ“„ License

MIT License - Educational purposes

---

**Last Updated**: October 4, 2025  
**Version**: 1.0.0  
**Status**: âœ… Phases 1-5 Complete | â¸ï¸ Phase 6 Pending
